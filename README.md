## Hi there ğŸ‘‹

I work at the intersection of machine learning research and production engineering, focusing on LLM-based agents, scalable ML systems, and performance-critical pipelines. My work emphasizes practical research translation â€” turning ideas into systems that hold up under real workloads.

ğŸ”¬ Research & Technical Interests

LLM-based Agents (planning, tool use, orchestration)

Representation Learning & Transformers

RAG systems and retrieval optimization

Model efficiency & system-level performance

Scalable ML infrastructure

ğŸ§  Current Focus

Designing cost-aware and resource-bounded AI agents

Improving language-server & IDE scalability for large workspaces

Studying failure modes of ML systems at scale

Bridging research prototypes â†’ production systems

ğŸ§ª Selected Work

AgentCostController
Cost-aware orchestration framework for multi-agent LLM systems, focusing on budget control, observability, and execution efficiency.

Full-Stack ML Systems
End-to-end systems combining React, FastAPI, PostgreSQL, and LLM backends, with emphasis on performance and reliability.

System Diagnostics & Optimization
Tooling and workflows to analyze memory pressure, worker leaks, and language-server scalability in modern developer environments.

ğŸ› ï¸ Technical Stack

Languages: Python, JavaScript, TypeScript

ML / AI: PyTorch, Transformers, RAG pipelines, Agents

Backend: FastAPI, Node.js

Databases: PostgreSQL, MySQL

Infra: Docker, Linux, WSL

Tooling: Git, GitHub Actions, Chrome DevTools

ğŸ“ˆ Engineering Philosophy

Research should fail loudly, early, and informatively

Scalability issues are design problems, not user problems

Tooling matters as much as models

Systems must be observable before they are optimized

ğŸ“« Contact

GitHub: https://github.com/mdkashifakram

Email / LinkedIn: (add if you want)

â­ Interested in roles that value both research thinking and production discipline.
